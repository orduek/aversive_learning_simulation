{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "231fb6cc-78f6-42b9-8ec9-fd9b5a8fda29",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/orduek/aversive_learning_simulation/blob/main/simulating_scrData.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9955d7f0-ab8b-4d1f-9802-0a0c1a864271",
   "metadata": {},
   "source": [
    "# Simulating and testing simple RW model\n",
    "In this notebook we will simulate SCR data of an aversive learning task\n",
    "- Simulate\n",
    "- Test Maximum Likelihood extraction\n",
    "- Test pymc3 model on the simulated data\n",
    "- Compare different models\n",
    "\\\n",
    "\n",
    "The notebook is heavily based on two these two great resources:\n",
    "1. https://github.com/ricardoV94/stats/blob/master/modelling/RL_PyMC.ipynb\n",
    "2. https://discourse.pymc.io/t/modeling-reinforcement-learning-of-human-participant-using-pymc3/1735"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fa48949-35c0-46ed-b470-3b20b8343074",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "import scipy\n",
    "import os\n",
    "# import stan\n",
    "\n",
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1732f5e4-c3bc-4847-8e8d-cd67b38f48eb",
   "metadata": {},
   "source": [
    "First we simulate vector of stimulus (CS+ = 1 and CS- = 0) \\\n",
    "Then simulate a vector of shocks (shock=1, no shock =0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab844ef2-946c-421d-ba9c-a5b7bfc6d4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0]\n",
      "[1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "stimVec = [1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0]\n",
    "shockVec = [1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0]\n",
    "print(stimVec)\n",
    "print(shockVec[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a70e162c-a38e-4765-a5fd-99e4bdb96c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "shockVec = np.hstack([shockVec] *1)\n",
    "stimVec = np.hstack([stimVec] * 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26377824-6bc4-4bcc-92ae-70373bdd9a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3888888888888889"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(shockVec) / sum(stimVec) # 38%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd37887-b2c3-4dcc-bb26-5b4acb676c39",
   "metadata": {},
   "source": [
    "# Simulate SCR based on stimulus and shock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8817fa90-3282-4973-a937-18b6f02b8b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulateSCR(alpha, stimVec, shockVec, intercept, slope):\n",
    "    scrSim = np.zeros(len(stimVec))\n",
    "    scrCSp = 0.5\n",
    "    scrCSm = 0.5\n",
    "    # set intercept and slopes\n",
    "    for i,(s,t) in enumerate(zip(stimVec,shockVec)):\n",
    "        # print(i)\n",
    "        # print(f'Stim is {s}')\n",
    "        # print(f'Shock is{t}')\n",
    "        if s==1:      \n",
    "            pe = t - scrCSp   # prediction error\n",
    "            scrCSp = scrCSp + alpha*pe\n",
    "            scrSim[i] = scrCSp\n",
    "        if s==0:\n",
    "            pe = t - scrCSm   # prediction error\n",
    "            scrCSm = scrCSm + alpha*pe\n",
    "            scrSim[i] = scrCSm\n",
    "        # add intercept and slope\n",
    "        scrSim[i] = scrSim[i] + np.random.normal(0,.1) # add noise #\n",
    "        \n",
    "        scrSim[i] =  slope*scrSim[i]\n",
    "        \n",
    "    return scrSim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ae9deb0-621c-4724-8634-ab61e014c576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 10 subjects with different alphas\n",
    "n_subj = 10 # number of subjects\n",
    "alphalist = []\n",
    "interceptList = []\n",
    "slopeList = []\n",
    "\n",
    "subjects = np.empty([shockVec.shape[0],n_subj]) # create an empty matrix of trials X subjects\n",
    "for i in np.arange(n_subj):\n",
    "   # print(i)\n",
    "    alpha = np.random.beta(a=1,b=1)\n",
    "    intercept = np.random.normal(0,1)\n",
    "    slope = np.random.normal(0,1)\n",
    "    subjects[:,i] = simulateSCR(alpha, stimVec, shockVec, intercept, slope)\n",
    "    alphalist.append(alpha)\n",
    "    interceptList.append(intercept)\n",
    "    slopeList.append(slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47165d29-2897-4837-9b6c-360cc3265763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 10)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558a804d-f380-4478-98a8-8b78a9716d13",
   "metadata": {},
   "source": [
    "# Test logp with MLE\n",
    "Here we first use the RW model to extract the $\\alpha$ (learning rate) of each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa5e61da-c1a7-45a1-9abc-a442de2ce7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llik_td(x, *args):\n",
    "    # Extract the arguments as they are passed by scipy.optimize.minimize\n",
    "    alpha, beta = x\n",
    "    stim, shock, scr  = args\n",
    "    \n",
    "    scrSim = np.zeros(len(stim))\n",
    "    scrCSp = 0.5\n",
    "    scrCSm = 0.5\n",
    "    # set intercept and slopes\n",
    "    for i,(s,t) in enumerate(zip(stim,shock)):\n",
    "       \n",
    "        if s==1:      \n",
    "            pe = t - scrCSp   # prediction error\n",
    "            scrCSp = scrCSp + alpha*pe\n",
    "            scrSim[i] = scrCSp\n",
    "        if s==0:\n",
    "            pe = t - scrCSm   # prediction error\n",
    "            scrCSm = scrCSm + alpha*pe\n",
    "            scrSim[i] = scrCSm\n",
    "        # add intercept and slope\n",
    "        scrSim[i] = scrSim[i] \n",
    "        \n",
    "        scrSim[i] =  beta*scrSim[i]\n",
    "   \n",
    "    scrPred = scrSim\n",
    "    # Calculate the log-likelihood for normal distribution\n",
    "    LL = np.sum(scipy.stats.norm.logpdf(scr, scrPred))\n",
    "    # Calculate the negative log-likelihood\n",
    "    neg_LL = -1*LL\n",
    "    return neg_LL \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a06d2d7-a90c-466c-89a8-26d16ca6815f",
   "metadata": {},
   "source": [
    "Optimizing the likelihood\n",
    "- We will get a list of alpha and slope per subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97ec69d6-9d87-4401-abf7-622d2f6d2679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.292833   -0.01585205]\n",
      "[ 0.89944305 -0.30031462]\n",
      "[ 0.92926854 -0.12836659]\n",
      "[0.08399216 1.68311358]\n",
      "[0.92642053 0.36312567]\n",
      "[0.27037335 0.97253865]\n",
      "[ 0.90282192 -0.26311115]\n",
      "[ 0.95320509 -1.12880985]\n",
      "[0.23337722 0.10064373]\n",
      "[ 0.82462496 -0.42777693]\n"
     ]
    }
   ],
   "source": [
    "logSub = []\n",
    "estLog = []\n",
    "for i in np.arange(n_subj):\n",
    "    x0 = [alphalist[i], slopeList[i]]\n",
    "    estLog.append(scipy.optimize.minimize(llik_td, x0, args=(stimVec,shockVec , subjects[:,i]), method='L-BFGS-B'))\n",
    "    print(estLog[i].x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332bea3b-b11e-4565-8584-99a8008c902c",
   "metadata": {},
   "source": [
    "Compare to actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecec04fe-76f8-4424-a801-d749983c4270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alphas [0.29253817378965086, 0.8629301947316974, 0.9246810700086434, 0.0801599312874431, 0.9090607385565922, 0.2453775296154726, 0.8575869746044947, 0.9479997945421589, 0.31071809024413805, 0.828829467455965]\n",
      "Slopes [-0.015350787397765684, -0.3399462576132514, -0.1234733395421933, 1.6323439504040627, 0.35801389799367195, 0.9187054477941142, -0.2870036842819805, -1.1198339578558987, 0.10485300159125356, -0.42076112688765976]\n"
     ]
    }
   ],
   "source": [
    "print(f'Alphas {alphalist}\\nSlopes {slopeList}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc56c973-7fe7-47b6-a924-b894ead38e1c",
   "metadata": {},
   "source": [
    "Recovery is relatively ok"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3760fbe-fbe2-4437-bca2-223f466f9906",
   "metadata": {},
   "source": [
    "# Test the PyMC code\n",
    "- We start with building an update_Q function that updates the value of of each stimulus in each trial\n",
    "- Because our observed variable is SCR per trial, we extract a vector with expected value per the relevant trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "977cb1a9-ab18-41f6-8088-3def85995785",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrs = tt.zeros(30) # set empty scr tensor (vector)\n",
    "   \n",
    "# generate functions to run\n",
    "def update_Q(stim, shock,\n",
    "             Qs,vec,\n",
    "             alpha, n_subj):\n",
    "    \"\"\"\n",
    "    This function updates the Q table according to the RL update rule.\n",
    "    It will be called by theano.scan to do so recursevely, given the observed data and the alpha parameter\n",
    "    This could have been replaced be the following lamba expression in the theano.scan fn argument:\n",
    "        fn=lamba action, reward, Qs, alpha: tt.set_subtensor(Qs[action], Qs[action] + alpha * (reward - Qs[action]))\n",
    "    \"\"\"\n",
    "     \n",
    "    PE = shock - Qs[tt.arange(n_subj), stim]\n",
    "    Qs = tt.set_subtensor(Qs[tt.arange(n_subj),stim], Qs[tt.arange(n_subj),stim] + alpha * PE)\n",
    "    \n",
    "    # in order to get a vector of expected outcome (dependent on the stimulus presentes [CS+, CS-] \n",
    "    # we us if statement (switch in theano)\n",
    "    vec = tt.set_subtensor(vec[tt.arange(n_subj),0], (tt.switch(tt.eq(stim,1), \n",
    "                                                                Qs[tt.arange(n_subj),1], Qs[tt.arange(n_subj),0])))\n",
    "    \n",
    "    return Qs, vec\n",
    "\n",
    "def theano_llik_td(alpha,  stim, shock, n_subj):\n",
    "   # stim = theano.shared(np.asarray(stim, dtype='int16'))\n",
    "   # shock = theano.shared(np.asarray(shock, dtype='int16'))\n",
    "\n",
    "    # Compute the Qs values\n",
    "    Qs = 0.5 * tt.ones((n_subj,2), dtype='float64') # set values for boths stimuli (CS+, CS-)\n",
    "    vec = 0.5 * tt.ones((n_subj,1), dtype='float64') # vector to save the relevant stimulus's expactation\n",
    "    [Qs,vec], updates = theano.scan(\n",
    "        fn=update_Q,\n",
    "        sequences=[stim, shock],\n",
    "        outputs_info=[Qs, vec],\n",
    "        non_sequences=[alpha, n_subj])\n",
    "    \n",
    "   \n",
    "    return Qs, vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dca2e2a-6326-4257-9f0e-7150f333385d",
   "metadata": {},
   "source": [
    "Now move everything to theano and generate indexing for subjects, trials etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6458a6af-f14e-445b-8f99-3e94cb916a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_subj = subjects.shape[1]\n",
    "n_trials=stimVec.shape[0]\n",
    "\n",
    "trials, subj = np.meshgrid(range(n_trials), range(n_subj))\n",
    "trials = tt.as_tensor_variable(trials.T)\n",
    "subj = tt.as_tensor_variable(subj.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f16a724f-7825-4884-9c9c-35088b53e0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize the vectors to feed\n",
    "stim =np.reshape([stimVec]*n_subj, (n_subj,n_trials)).T # transform to matrix trials x subject\n",
    "shock = np.reshape([shockVec]*n_subj, (n_subj,n_trials)).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8a0f0b9-a314-44ae-988d-6691c58f0c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn to tensores\n",
    "stim = tt.as_tensor_variable(stim)\n",
    "shock = tt.as_tensor_variable(shock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7a5c3fd1-2331-4ba8-94ca-4fb61f52695c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the function first\n",
    "results, vec = theano_llik_td(alphalist, stim, shock, n_subj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fcc670e5-e382-43fc-b6ce-dd99c305c762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 10, 1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.eval().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa86e78-0fe7-47ba-984f-c549d411cc4a",
   "metadata": {},
   "source": [
    "# Now Comparing Different Models\n",
    "- Now we can test which of the models recovers the known $\\alpha$ from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "70f05a6c-0814-4f5c-9813-e2845e279efe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 10 jobs)\n",
      "NUTS: [eps, beta, alpha]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 01:37<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 99 seconds.\n"
     ]
    }
   ],
   "source": [
    "# try alpha as beta distribution\n",
    "with pm.Model() as mB:\n",
    "    \n",
    "   # betaHyper= pm.Normal('betaH', 0, 1)\n",
    "    alpha = pm.Beta('alpha', 1,1, shape=n_subj)\n",
    "    beta = pm.Normal('beta',0, 1, shape=n_subj)\n",
    "    eps = pm.HalfNormal('eps', 5)\n",
    "    \n",
    "    Qs = 0.5 * tt.ones((n_subj,2), dtype='float64') # set values for boths stimuli (CS+, CS-)\n",
    "    vec = 0.5 * tt.ones((n_subj,1), dtype='float64') # vector to save the relevant stimulus's expactation\n",
    "    \n",
    "    [Qs,vec], updates = theano.scan(\n",
    "        fn=update_Q,\n",
    "        sequences=[stim, shock],\n",
    "        outputs_info=[Qs, vec],\n",
    "        non_sequences=[alpha, n_subj])\n",
    "   \n",
    "    \n",
    "    vec_ = vec[trials,subj,0] * beta[subj]\n",
    "    \n",
    "    scrs = pm.Normal('scrs', vec_, eps, observed=subjects) \n",
    "    \n",
    "    # add matrix of expected values (trials X subjects)\n",
    "    ev = pm.Deterministic('expected_value', vec_)\n",
    "    \n",
    "    trB = pm.sample(target_accept=.9, chains=4, cores=10, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0f990f23-9cf3-473e-aec3-84b81567268e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>0.140</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2824.0</td>\n",
       "      <td>1512.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[1]</th>\n",
       "      <td>0.709</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>3882.0</td>\n",
       "      <td>2135.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[2]</th>\n",
       "      <td>0.300</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5138.0</td>\n",
       "      <td>3242.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[3]</th>\n",
       "      <td>0.744</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.472</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>3799.0</td>\n",
       "      <td>1847.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[4]</th>\n",
       "      <td>0.462</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>4613.0</td>\n",
       "      <td>2604.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[5]</th>\n",
       "      <td>0.390</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>3367.0</td>\n",
       "      <td>1756.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[6]</th>\n",
       "      <td>0.696</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3532.0</td>\n",
       "      <td>2910.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[7]</th>\n",
       "      <td>0.709</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4274.0</td>\n",
       "      <td>2237.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[8]</th>\n",
       "      <td>0.572</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3808.0</td>\n",
       "      <td>2549.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[9]</th>\n",
       "      <td>0.517</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>3015.0</td>\n",
       "      <td>2116.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "alpha[0]  0.140  0.081   0.010    0.291      0.001    0.001    2824.0   \n",
       "alpha[1]  0.709  0.182   0.397    0.999      0.003    0.002    3882.0   \n",
       "alpha[2]  0.300  0.017   0.269    0.332      0.000    0.000    5138.0   \n",
       "alpha[3]  0.744  0.159   0.472    1.000      0.002    0.002    3799.0   \n",
       "alpha[4]  0.462  0.269   0.021    0.921      0.004    0.003    4613.0   \n",
       "alpha[5]  0.390  0.234   0.003    0.815      0.004    0.003    3367.0   \n",
       "alpha[6]  0.696  0.020   0.659    0.731      0.000    0.000    3532.0   \n",
       "alpha[7]  0.709  0.070   0.577    0.841      0.001    0.001    4274.0   \n",
       "alpha[8]  0.572  0.061   0.457    0.689      0.001    0.001    3808.0   \n",
       "alpha[9]  0.517  0.177   0.190    0.847      0.003    0.002    3015.0   \n",
       "\n",
       "          ess_tail  r_hat  \n",
       "alpha[0]    1512.0    1.0  \n",
       "alpha[1]    2135.0    1.0  \n",
       "alpha[2]    3242.0    1.0  \n",
       "alpha[3]    1847.0    1.0  \n",
       "alpha[4]    2604.0    1.0  \n",
       "alpha[5]    1756.0    1.0  \n",
       "alpha[6]    2910.0    1.0  \n",
       "alpha[7]    2237.0    1.0  \n",
       "alpha[8]    2549.0    1.0  \n",
       "alpha[9]    2116.0    1.0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(trB, var_names='alpha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1a264a4d-6ae4-40d5-804e-8a9f5e08489a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08598412304674652, 0.8251625236377906, 0.37879936207637654, 0.8504167076811493, 0.2144552072802054, 0.2597169394236822, 0.7176683939162277, 0.7233651693601585, 0.59028091283681, 0.5139323281223185]\n"
     ]
    }
   ],
   "source": [
    "#slopeList\n",
    "print(alphalist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6174f5-f6fd-46b3-b09f-90e1f9ef9515",
   "metadata": {},
   "source": [
    "## Recovering ok but not perfect\n",
    "- Lets add hierarchy to see how helpful this can be"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d11aa3b-cc97-4ee5-b3c4-fd1988c5a903",
   "metadata": {},
   "source": [
    "## Use both $\\alpha$ and $\\beta$ as pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a9a2a937-86b3-4f82-922a-958323207294",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 8 jobs)\n",
      "NUTS: [eps, beta, beta_sd, beta_h, alpha, kappa_log, phi]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 02:10<00:00 Sampling 4 chains, 2 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 132 seconds.\n",
      "There were 2 divergences after tuning. Increase `target_accept` or reparameterize.\n"
     ]
    }
   ],
   "source": [
    "# try alpha as beta distribution\n",
    "with pm.Model() as m_H:\n",
    "    \n",
    "    phi = pm.Uniform(\"phi\", lower=0.0, upper=1.0)\n",
    "\n",
    "    kappa_log = pm.Exponential(\"kappa_log\", lam=1.5)\n",
    "    kappa = pm.Deterministic(\"kappa\", tt.exp(kappa_log))\n",
    "\n",
    "    alpha = pm.Beta(\"alpha\", alpha=phi * kappa, beta=(1.0 - phi) * kappa, shape=n_subj)\n",
    "    \n",
    "    \n",
    "    beta_h = pm.Normal('beta_h', 0,1)\n",
    "    beta_sd = pm.HalfNormal('beta_sd', 1)\n",
    "    beta = pm.Normal('beta',beta_h, beta_sd, shape=n_subj)\n",
    "       \n",
    "    eps = pm.HalfNormal('eps', 5)\n",
    "    \n",
    "    Qs = 0.5 * tt.ones((n_subj,2), dtype='float64') # set values for boths stimuli (CS+, CS-)\n",
    "    vec0 = 0.5 * tt.ones((n_subj,1), dtype='float64') # vector to save the relevant stimulus's expactation\n",
    "    \n",
    "    [Qs,vec], updates = theano.scan(\n",
    "        fn=update_Q,\n",
    "        sequences=[stim, shock],\n",
    "        outputs_info=[Qs, vec0],\n",
    "        non_sequences=[alpha, n_subj])\n",
    "   \n",
    "     \n",
    "    vec_ = vec[trials, subj,0] * beta[subj]\n",
    "    \n",
    "    scrs = pm.Normal('scrs', vec_, eps, observed=subjects) \n",
    "    \n",
    "    # add matrix of expected values (trials X subjects)\n",
    "    ev = pm.Deterministic('expected_value', vec_)\n",
    "    \n",
    "    tr_hB = pm.sample(target_accept=.9, chains=4, cores=8, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "19376a75-bd99-4c9b-ba96-68b094f48df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>0.167</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2615.0</td>\n",
       "      <td>1286.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[1]</th>\n",
       "      <td>0.690</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.380</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>3159.0</td>\n",
       "      <td>1739.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[2]</th>\n",
       "      <td>0.301</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5694.0</td>\n",
       "      <td>2192.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[3]</th>\n",
       "      <td>0.722</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.466</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>2861.0</td>\n",
       "      <td>1420.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[4]</th>\n",
       "      <td>0.492</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>4175.0</td>\n",
       "      <td>2468.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[5]</th>\n",
       "      <td>0.422</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>3377.0</td>\n",
       "      <td>1603.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[6]</th>\n",
       "      <td>0.696</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3999.0</td>\n",
       "      <td>2680.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[7]</th>\n",
       "      <td>0.703</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3900.0</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[8]</th>\n",
       "      <td>0.571</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4587.0</td>\n",
       "      <td>2607.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[9]</th>\n",
       "      <td>0.523</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2768.0</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "alpha[0]  0.167  0.102   0.000    0.343      0.002    0.001    2615.0   \n",
       "alpha[1]  0.690  0.183   0.380    1.000      0.003    0.002    3159.0   \n",
       "alpha[2]  0.301  0.017   0.268    0.332      0.000    0.000    5694.0   \n",
       "alpha[3]  0.722  0.159   0.466    1.000      0.003    0.002    2861.0   \n",
       "alpha[4]  0.492  0.251   0.053    0.955      0.004    0.003    4175.0   \n",
       "alpha[5]  0.422  0.229   0.015    0.836      0.004    0.003    3377.0   \n",
       "alpha[6]  0.696  0.020   0.660    0.735      0.000    0.000    3999.0   \n",
       "alpha[7]  0.703  0.071   0.576    0.842      0.001    0.001    3900.0   \n",
       "alpha[8]  0.571  0.058   0.460    0.680      0.001    0.001    4587.0   \n",
       "alpha[9]  0.523  0.168   0.200    0.842      0.003    0.003    2768.0   \n",
       "\n",
       "          ess_tail  r_hat  \n",
       "alpha[0]    1286.0    1.0  \n",
       "alpha[1]    1739.0    1.0  \n",
       "alpha[2]    2192.0    1.0  \n",
       "alpha[3]    1420.0    1.0  \n",
       "alpha[4]    2468.0    1.0  \n",
       "alpha[5]    1603.0    1.0  \n",
       "alpha[6]    2680.0    1.0  \n",
       "alpha[7]    2700.0    1.0  \n",
       "alpha[8]    2607.0    1.0  \n",
       "alpha[9]    1297.0    1.0  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(tr_hB, var_names='alpha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3df59b15-77b2-419d-8fb5-dc45411d7d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08598412304674652, 0.8251625236377906, 0.37879936207637654, 0.8504167076811493, 0.2144552072802054, 0.2597169394236822, 0.7176683939162277, 0.7233651693601585, 0.59028091283681, 0.5139323281223185]\n"
     ]
    }
   ],
   "source": [
    "print(alphalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1589b314-9fa2-4249-b9d6-5acb38a50b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/or/miniconda3/envs/neuroAnalysis/lib/python3.7/site-packages/arviz/stats/stats.py:695: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n",
      "  \"Estimated shape parameter of Pareto distribution is greater than 0.7 for \"\n",
      "/home/or/miniconda3/envs/neuroAnalysis/lib/python3.7/site-packages/arviz/stats/stats.py:695: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n",
      "  \"Estimated shape parameter of Pareto distribution is greater than 0.7 for \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>loo</th>\n",
       "      <th>p_loo</th>\n",
       "      <th>d_loo</th>\n",
       "      <th>weight</th>\n",
       "      <th>se</th>\n",
       "      <th>dse</th>\n",
       "      <th>warning</th>\n",
       "      <th>loo_scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model1</th>\n",
       "      <td>0</td>\n",
       "      <td>389.454238</td>\n",
       "      <td>24.852449</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.360882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model2</th>\n",
       "      <td>1</td>\n",
       "      <td>388.960479</td>\n",
       "      <td>25.082666</td>\n",
       "      <td>0.49376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.375920</td>\n",
       "      <td>0.345765</td>\n",
       "      <td>True</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rank         loo      p_loo    d_loo  weight         se       dse  \\\n",
       "model1     0  389.454238  24.852449  0.00000     1.0  28.360882  0.000000   \n",
       "model2     1  388.960479  25.082666  0.49376     0.0  28.375920  0.345765   \n",
       "\n",
       "        warning loo_scale  \n",
       "model1     True       log  \n",
       "model2     True       log  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp = az.compare({'model1':trB, 'model2': tr_hB}, ic='loo')\n",
    "comp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad97bee-cb47-463c-9d36-8abc148655de",
   "metadata": {},
   "source": [
    "Models perform relatively the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "de932a79-66d3-4275-b51e-51682563326a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Log'>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "az.plot_compare(comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a6d49e-d9ea-4b82-95e9-7622bb9516af",
   "metadata": {},
   "source": [
    "# Correlate expected value and subject data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2ac12951-c2ad-4381-8e35-6a0bea3ccd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack all chains\n",
    "a = trB.posterior.stack(draws=('chain','draw'))\n",
    "a = a.expected_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "00a86024-18be-41ab-bee7-914329b8c525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 10)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_a = np.mean(a, axis=2)\n",
    "mean_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3d13b6ba-ca31-40fc-9c06-07f2cd6e9e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7580964634564524, 1.2195238400051906e-06)\n",
      "(0.9482221842617782, 1.773841236203829e-15)\n",
      "(0.8860133424930073, 7.529099386035203e-11)\n",
      "(0.9612313225744649, 3.346646126642093e-17)\n",
      "(0.7902888769801648, 2.051125749112005e-07)\n",
      "(0.8410364382994959, 5.927888218925415e-09)\n",
      "(0.9734795343356426, 1.7731851926101837e-19)\n",
      "(0.960113878599536, 4.9474930105288993e-17)\n",
      "(0.9523743701437635, 5.647518480809706e-16)\n",
      "(0.9481073973549226, 1.8283924944317867e-15)\n"
     ]
    }
   ],
   "source": [
    "# calculate \n",
    "for i in np.arange(10):\n",
    "    cor1 = scipy.stats.pearsonr(subjects[:,i], mean_a[:,i])\n",
    "    print(cor1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc52d49-d1ab-43da-9548-b2dbe2def11c",
   "metadata": {},
   "source": [
    "# The Pearce-Hall Hybrid model\n",
    "This is an attempt to build the PH Hybrid model.\n",
    "This model doesn't assume a simple constant learning rate (as the RW), rather, it incorporated both a constant learning rate and a dynamic one. The dynamic one is being updated by the amount of new information given.\n",
    "The model goes like that: \\\n",
    "(1) Vi(k+1) = Vi (k) + $\\kappa \\alpha$(k)$\\delta$ \\\n",
    "(2) $\\delta$ = shock - Vi(k) \\\n",
    "(3) $\\alpha$(k+1) = $\\eta |\\delta|$ + (1 - $\\eta)\\alpha$(k)\n",
    "\n",
    "So the current value is an update of the previous one plus a constant learning rate (kappa) and an associability weight (alpha) (times the delta = prediction error)\n",
    "The $\\alpha$ is set by a constant weight of associability (eta) and the previous $\\alpha$ \\\n",
    "\n",
    "So now, our updating function will include those elements as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "269c29b3-9738-427c-9b08-b69c520f652c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate functions to run\n",
    "def update_Q(stim, shock,\n",
    "             Qs,vec,alpha,assoc,\n",
    "             eta,kappa, n_subj):\n",
    "    \"\"\"\n",
    "    This function updates the Q table according to Hybrid PH model\n",
    "    For information, please see this paper: https://www.sciencedirect.com/science/article/pii/S0896627316305840?via%3Dihub\n",
    "  \n",
    "    \"\"\"\n",
    "      \n",
    "    delta = shock - Qs[tt.arange(n_subj), stim]\n",
    "    alpha = tt.set_subtensor(alpha[tt.arange(n_subj), stim], eta * abs(delta) + (1-eta)*alpha[tt.arange(n_subj), stim])\n",
    "    Qs = tt.set_subtensor(Qs[tt.arange(n_subj),stim], Qs[tt.arange(n_subj),stim] + kappa*alpha[tt.arange(n_subj), stim] * delta)\n",
    "    \n",
    "    # in order to get a vector of expected outcome (dependent on the stimulus presentes [CS+, CS-] \n",
    "    # we us if statement (switch in theano)\n",
    "    vec = tt.set_subtensor(vec[tt.arange(n_subj),0], (tt.switch(tt.eq(stim,1), \n",
    "                                                                Qs[tt.arange(n_subj),1], Qs[tt.arange(n_subj),0])))\n",
    "    \n",
    "    # we use the same idea to get the associability per trial\n",
    "    assoc = tt.set_subtensor(assoc[tt.arange(n_subj),0], (tt.switch(tt.eq(stim,1), \n",
    "                                                                alpha[tt.arange(n_subj),1], alpha[tt.arange(n_subj),0])))\n",
    "    \n",
    "    return Qs, vec, alpha, assoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0ac20c8-b8c5-4e61-be9c-39a6d8212cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 10 jobs)\n",
      "NUTS: [eps, , k_log2, beta, beta_sd, beta_h, kappa, k_log1, phi]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 06:35<00:00 Sampling 4 chains, 8 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/or/miniconda3/envs/neuroAnalysis/lib/python3.7/site-packages/pymc3/step_methods/hmc/integration.py:108: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  energy = kinetic - logp\n",
      "/home/or/miniconda3/envs/neuroAnalysis/lib/python3.7/site-packages/pymc3/step_methods/hmc/integration.py:108: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  energy = kinetic - logp\n",
      "/home/or/miniconda3/envs/neuroAnalysis/lib/python3.7/site-packages/pymc3/step_methods/hmc/integration.py:108: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  energy = kinetic - logp\n",
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 397 seconds.\n",
      "There were 3 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 4 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as m:\n",
    "  \n",
    "    # hyperpriors for eta and kappa\n",
    "    phi = pm.Uniform(\"phi\", lower=0.0, upper=1.0, shape=2)\n",
    "    \n",
    "    #    \n",
    "    k_log1 = pm.Exponential(\"k_log1\", lam=1.5)\n",
    "    k1 = pm.Deterministic(\"k1\", tt.exp(k_log1))\n",
    "    kappa = pm.Beta(\"kappa\", alpha=phi[0] * k1, beta=(1.0 - phi[0]) * k1, shape=n_subj)\n",
    "    \n",
    "    # \n",
    "    beta_h = pm.Normal('beta_h', 0,1)\n",
    "    beta_sd = pm.HalfNormal('beta_sd', 5)\n",
    "    beta = pm.Normal('beta',beta_h, beta_sd, shape=n_subj)\n",
    "    \n",
    "    # \n",
    "    k_log2 = pm.Exponential(\"k_log2\", lam=1.5)\n",
    "    k2 = pm.Deterministic(\"k2\", tt.exp(k_log2))\n",
    "    eta = pm.Beta('', alpha=phi[1] * k2, beta=(1.0 - phi[1]) * k2, shape=n_subj)\n",
    "    \n",
    "   # kappa = pm.Beta('kappa', 1,1, shape=n_subj)\n",
    "   # eta = pm.Beta('eta', 1,1, shape=n_subj)\n",
    "    \n",
    "  #  beta = pm.Normal('beta',0, 1, shape=n_subj)\n",
    "    eps = pm.HalfNormal('eps', 5)\n",
    "    \n",
    "    Qs = 0.5 * tt.ones((n_subj,2), dtype='float64') # set values for boths stimuli (CS+, CS-)\n",
    "    vec = 0.5 * tt.ones((n_subj,1), dtype='float64') # vector to save the relevant stimulus's expactation\n",
    "    alpha = 0 * tt.ones((n_subj,2), dtype='float64')\n",
    "    assoc = 0 * tt.ones((n_subj,1), dtype='float64')\n",
    "    \n",
    "    [Qs,vec, alpha, assoc], updates = theano.scan(\n",
    "        fn=update_Q,\n",
    "        sequences=[stim, shock],\n",
    "        outputs_info=[Qs, vec, alpha, assoc],\n",
    "        non_sequences=[eta, kappa, n_subj])\n",
    "   \n",
    "    \n",
    "    vec_ = vec[trials, subj,0] * beta[subj]\n",
    "    \n",
    "    scrs = pm.Normal('scrs', vec_, eps, observed=subjects) \n",
    "    \n",
    "    # add matrix of expected values (trials X subjects)\n",
    "    ev = pm.Deterministic('expected_value', vec_)\n",
    "    # add associabillity\n",
    "    #assoc = pm.Deterministic('alpha', assoc)\n",
    "    \n",
    "    tr = pm.sample(target_accept=.9, chains=4, cores=10, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "127d9926-a6d0-444e-bf06-e3df66582abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>[0]</th>\n",
       "      <td>0.624</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.185</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1275.0</td>\n",
       "      <td>1215.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[1]</th>\n",
       "      <td>0.631</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.104</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1455.0</td>\n",
       "      <td>1233.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[2]</th>\n",
       "      <td>0.701</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.182</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.008</td>\n",
       "      <td>511.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[3]</th>\n",
       "      <td>0.649</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.418</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>1685.0</td>\n",
       "      <td>888.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[4]</th>\n",
       "      <td>0.615</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.098</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.004</td>\n",
       "      <td>1787.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[5]</th>\n",
       "      <td>0.537</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>2948.0</td>\n",
       "      <td>1593.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[6]</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.800</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>824.0</td>\n",
       "      <td>693.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[7]</th>\n",
       "      <td>0.676</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.178</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.008</td>\n",
       "      <td>576.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[8]</th>\n",
       "      <td>0.441</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2966.0</td>\n",
       "      <td>2116.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[9]</th>\n",
       "      <td>0.493</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.038</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.006</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>897.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  ess_tail  \\\n",
       "[0]  0.624  0.264   0.185    1.000      0.007    0.005    1275.0    1215.0   \n",
       "[1]  0.631  0.295   0.104    1.000      0.007    0.005    1455.0    1233.0   \n",
       "[2]  0.701  0.266   0.182    1.000      0.011    0.008     511.0     282.0   \n",
       "[3]  0.649  0.161   0.418    1.000      0.004    0.003    1685.0     888.0   \n",
       "[4]  0.615  0.296   0.098    1.000      0.006    0.004    1787.0    1140.0   \n",
       "[5]  0.537  0.145   0.282    0.821      0.003    0.002    2948.0    1593.0   \n",
       "[6]  0.935  0.068   0.800    1.000      0.002    0.001     824.0     693.0   \n",
       "[7]  0.676  0.270   0.178    1.000      0.011    0.008     576.0     270.0   \n",
       "[8]  0.441  0.086   0.283    0.600      0.002    0.001    2966.0    2116.0   \n",
       "[9]  0.493  0.309   0.038    1.000      0.009    0.006    1003.0     897.0   \n",
       "\n",
       "      r_hat  \n",
       "[0]   1.00  \n",
       "[1]   1.00  \n",
       "[2]   1.01  \n",
       "[3]   1.00  \n",
       "[4]   1.00  \n",
       "[5]   1.00  \n",
       "[6]   1.00  \n",
       "[7]   1.01  \n",
       "[8]   1.00  \n",
       "[9]   1.00  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(tr, var_names='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233c107f-fc52-42ed-a5d7-d000a01f4294",
   "metadata": {},
   "source": [
    "Not surprising, but this model doesn't fit the current simulated data so well. Which is reasonable, as the simulation was built based on the RW model.\n",
    "I hope to build a more specific simulation for the PH model later on. For now, we just keep it as an example"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
